{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c003dccf-c23f-45c3-8ddc-73fb2549bad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from glob import glob\n",
    "import tensorflow_model_optimization as tfmot\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import random\n",
    "import gc\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "def setup_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "\n",
    "setup_seed(1)\n",
    "\n",
    "gc.collect()\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "train_data_dir = 'path/to/train'\n",
    "validation_data_dir = 'path/to/validation'\n",
    "test_data_dir = 'path/to/test'\n",
    "\n",
    "batches = 32\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batches,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batches,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "def get_class_names(directory):\n",
    "    return sorted(os.listdir(directory))\n",
    "\n",
    "class_names = get_class_names(train_data_dir)\n",
    "class_indices = {class_name: index for index, class_name in enumerate(class_names)}\n",
    "\n",
    "for class_name, index in class_indices.items():\n",
    "    print(f\"Class Name: {class_name}, Index: {index}\")\n",
    "\n",
    "def load_and_resize_image(image_path, target_size=(224, 224)):  \n",
    "    image = cv2.imread(image_path)\n",
    "    image = cv2.resize(image, target_size)\n",
    "    image = image.astype('float32') / 255.0\n",
    "    return image\n",
    "\n",
    "def process_dataset(directory, batch_size, datagen, target_size=(224, 224)):  \n",
    "    image_paths = glob(os.path.join(directory, '*/*.png'))\n",
    "    random.shuffle(image_paths)\n",
    "    count = len(image_paths)\n",
    "    while True:\n",
    "        for i in range(0, count, batch_size):\n",
    "            batch_paths = image_paths[i:i+batch_size]\n",
    "            images = []\n",
    "            labels = []\n",
    "            for path in batch_paths:\n",
    "                img = load_and_resize_image(path, target_size)\n",
    "                images.append(img)\n",
    "                label = path.split(os.sep)[-2]\n",
    "                label_index = class_indices[label]  \n",
    "                labels.append(label_index)\n",
    "            labels = to_categorical(labels, num_classes=len(class_names))\n",
    "            yield np.array(images), np.array(labels)\n",
    "\n",
    "def get_class_sample_counts(directory, class_indices):\n",
    "    counts = {}\n",
    "    for class_name in class_indices.keys():\n",
    "        path = os.path.join(directory, class_name)\n",
    "        counts[class_name] = len(glob(os.path.join(path, '*.png')))\n",
    "    return counts\n",
    "\n",
    "class_sample_counts = get_class_sample_counts(train_data_dir, class_indices)\n",
    "samples_per_class = list(class_sample_counts.values())\n",
    "\n",
    "class_weights = compute_class_weight(class_weight='balanced',\n",
    "                                     classes=np.unique(list(class_indices.values())),\n",
    "                                     y=list(class_indices.values()) * (sum(samples_per_class) // len(samples_per_class)))\n",
    "class_weight_dict = dict(zip(np.unique(list(class_indices.values())), class_weights))\n",
    "\n",
    "batches = 32 #adjust as needed\n",
    "\n",
    "model = load_model('path/to/tensorflow/model') #requires a tensorflow model\n",
    "\n",
    "# Evaluate the loaded model if needed\n",
    "test_loss, test_accuracy = model.evaluate(\n",
    "    test_generator,\n",
    "    steps=len(glob(os.path.join(test_data_dir, '*/*.png'))) // batches\n",
    ")\n",
    "print(f\"Loaded Model Test Loss: {test_loss}\")\n",
    "print(f\"Loaded Model Test Accuracy: {test_accuracy}\")\n",
    "\n",
    "def print_model_weights_sparsity(model):\n",
    "    for layer in model.layers:\n",
    "        if isinstance(layer, tf.keras.layers.Wrapper):\n",
    "            weights = layer.trainable_weights\n",
    "        else:\n",
    "            weights = layer.weights\n",
    "        \n",
    "        for weight in weights:\n",
    "            if \"quantize_layer\" in weight.name:\n",
    "                continue  # Skip auxiliary quantization weights\n",
    "            \n",
    "            weight_numpy = weight.numpy()  # Convert to numpy array for processing\n",
    "            weight_size = weight_numpy.size\n",
    "            zero_num = np.count_nonzero(weight_numpy == 0)\n",
    "            \n",
    "            print(\n",
    "                f\"{weight.name}: {zero_num/weight_size:.2%} sparsity \",\n",
    "                f\"({zero_num}/{weight_size})\"\n",
    "            )\n",
    "\n",
    "prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "pruning_params = {\n",
    "    'pruning_schedule': tfmot.sparsity.keras.ConstantSparsity(0.5, begin_step=0, frequency=100)\n",
    "}\n",
    "\n",
    "callbacks = [\n",
    "    tfmot.sparsity.keras.UpdatePruningStep()\n",
    "]\n",
    "\n",
    "pruned_model = prune_low_magnitude(model, **pruning_params)\n",
    "\n",
    "opt = Adam(learning_rate=5e-5)\n",
    "\n",
    "pruned_model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer=opt,\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Make sure to create train_generator and validation_generator appropriately\n",
    "pruned_model.fit(\n",
    "    train_generator,\n",
    "    epochs=1,\n",
    "    steps_per_epoch=len(glob(os.path.join(train_data_dir, '*/*.png'))) // batches,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(glob(os.path.join(validation_data_dir, '*/*.png'))) // batches,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "stripped_pruned_model = tfmot.sparsity.keras.strip_pruning(pruned_model)\n",
    "\n",
    "print_model_weights_sparsity(stripped_pruned_model)\n",
    "\n",
    "_, pruned_model_accuracy = pruned_model.evaluate(\n",
    "    test_generator,\n",
    "    steps=len(glob(os.path.join(test_data_dir, '*/*.png'))) // batches\n",
    ")\n",
    "\n",
    "# PQAT\n",
    "quant_aware_annotate_model = tfmot.quantization.keras.quantize_annotate_model(\n",
    "              stripped_pruned_model)\n",
    "pqat_model = tfmot.quantization.keras.quantize_apply(\n",
    "              quant_aware_annotate_model,\n",
    "              tfmot.experimental.combine.Default8BitPrunePreserveQuantizeScheme())\n",
    "\n",
    "opt = Adam(learning_rate=1e-1) #adjust as needed\n",
    "pqat_model.compile(\n",
    "  loss='categorical_crossentropy',\n",
    "  optimizer=opt,\n",
    "  metrics=['accuracy']\n",
    ")\n",
    "\n",
    "print('Train pqat model:')\n",
    "\n",
    "pqat_model.fit(\n",
    "    train_generator,\n",
    "    epochs=1,\n",
    "    steps_per_epoch=len(glob(os.path.join(train_data_dir, '*/*.png'))) // batches,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=len(glob(os.path.join(validation_data_dir, '*/*.png'))) // batches,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "pqat_model.evaluate(\n",
    "    test_generator,\n",
    "    steps=len(glob(os.path.join(test_data_dir, '*/*.png'))) // batches\n",
    ")\n",
    "\n",
    "# Convert the TensorFlow model to a TensorFlow Lite model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(pqat_model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the TensorFlow Lite model to a file\n",
    "with open('model.tflite', 'wb') as f: #Change the model name to an appropriate name\n",
    "    f.write(tflite_model)\n",
    "\n",
    "# Convert the TensorFlow model to TensorFlow Lite with integer quantization\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(pqat_model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "converter.inference_input_type = tf.uint8  # or tf.int8\n",
    "converter.inference_output_type = tf.uint8  # or tf.int8\n",
    "converter.representative_dataset = representative_data_gen  # This needs to be set up\n",
    "\n",
    "def representative_data_gen():\n",
    "    for input_value, _ in train_generator:\n",
    "        yield [input_value]\n",
    "\n",
    "tflite_quant_model = converter.convert()\n",
    "\n",
    "# Save the quantized model\n",
    "with open('quant_model.tflite', 'wb') as f:\n",
    "    f.write(tflite_quant_model)\n",
    "\n",
    "# To compile the model for Edge TPU, you need to use the Edge TPU Compiler, which is a separate utility\n",
    "# This step cannot be done in Python and needs to be executed in a command line\n",
    "# Example command: edgetpu_compiler quant_model.tflite\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
